# -*- coding: utf-8 -*-
"""Copy of TeamLima_Pionexx_Code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13chnnJSMpLoIx5z2NU2IaLTB-gLaIr1o
"""

from google.colab import drive # Finalized Code ||
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import csv
import re # Import the re module for regular expressions


# Replace 'Your Folder Path' with the actual path to your CSV file in Google Drive
file_path = '/content/drive/MyDrive/Protexxa/pionex/241k-Singapore-pionex.com-Crypto-Trading-Bots-UsersDB-csv-2023.csv' # Assign the file path to a variable
df = pd.read_csv(file_path)

print(df.head(20)) # Display the first few rows of the dataframe

garbage_bin = pd.DataFrame()
garbage_bin

garbage_bin = df[['BrandCode', 'Lang']]
df = df.drop(['BrandCode', 'Lang'], axis=1)
print(df.head(20))
print(garbage_bin.head(20))

# Convert 'RegistrationDate' to datetime objects if it's not already
df['RegistrationDate'] = pd.to_datetime(df['RegistrationDate'], errors='coerce')

# Create new columns for Date and Time
df['Registration Date'] = df['RegistrationDate'].dt.date
df['Registration Time'] = df['RegistrationDate'].dt.time

# Drop original RegistrationDate column if no longer needed
df = df.drop('RegistrationDate', axis=1)

print(df.head(20))

# Apply the standardization function to the 'First Name' and 'Last Name' columns
df['First Name'] = df['First Name'].str.title()
df['Last Name'] = df['Last Name'].str.title()

print(df.head(20))

# Assuming 'df' is your DataFrame and it has columns 'First Name' and 'Last Name'
df[['First Name_new', 'Last Name_new']] = df['First Name'].str.split(' ', n=1, expand=True) # Changed from positional argument to keyword argument

# Fill NaN values in 'Last Name_new' with empty strings
df['Last Name_new'] = df['Last Name_new'].fillna('')

# Combine the original 'Last Name' with the new 'Last Name_new'
df['Last Name_new'] = df['Last Name'] + ' ' + df['Last Name_new']


# Drop the original 'First Name' and 'Last Name' columns
df = df.drop(['First Name', 'Last Name'], axis=1)

# Rename the new columns to the original names
df = df.rename(columns={'First Name_new': 'First Name', 'Last Name_new': 'Last Name'})

print(df.head(20))

# Remove rows with missing values in 'First Name' or 'Last Name'
missing_values_rows = df[df['First Name'].isna() | df['Last Name'].isna()]
garbage_bin = pd.concat([garbage_bin, missing_values_rows], ignore_index=True)
df = df.dropna(subset=['First Name', 'Last Name'])

# Function to check if a string contains any numbers
def contains_numbers(s):
  return any(char.isdigit() for char in s)

# Identify rows where 'First Name' or 'Last Name' contain numbers
rows_with_numbers = df[df['First Name'].apply(contains_numbers) | df['Last Name'].apply(contains_numbers)]

# Move those rows to the garbage_bin DataFrame
garbage_bin = pd.concat([garbage_bin, rows_with_numbers], ignore_index=True)

# Remove those rows from the original DataFrame
df = df[~df['First Name'].apply(contains_numbers) & ~df['Last Name'].apply(contains_numbers)]

# Drop rows with single value in 'First Name' or 'Last Name'
single_value_rows = df[df['First Name'].apply(lambda x: len(str(x)) <=1) | df['Last Name'].apply(lambda x: len(str(x)) <= 1)]
garbage_bin = pd.concat([garbage_bin, single_value_rows], ignore_index=True)
df = df[~df['First Name'].apply(lambda x: len(str(x)) <= 1) & ~df['Last Name'].apply(lambda x: len(str(x)) <= 1)]

# Define special characters to remove
special_chars = ['@', '%', '$', '#', '_']

# Function to check for special characters
def contains_special_chars(text):
  for char in special_chars:
    if char in str(text):
      return True
  return False

# Drop rows with special characters in 'First Name' or 'Last Name'
special_char_rows = df[df['First Name'].apply(contains_special_chars) | df['Last Name'].apply(contains_special_chars)]
garbage_bin = pd.concat([garbage_bin, special_char_rows], ignore_index = True)
df = df[~df['First Name'].apply(contains_special_chars) & ~df['Last Name'].apply(contains_special_chars)]

# Drop rows with missing values in 'Registration Date' or 'Registration Time'
missing_registration_rows = df[df['Registration Date'].isna() | df['Registration Time'].isna()]
garbage_bin = pd.concat([garbage_bin, missing_registration_rows], ignore_index=True)
df = df.dropna(subset=['Registration Date', 'Registration Time'])

# Convert 'Registration Date' to datetime objects if it's not already
df['Registration Date'] = pd.to_datetime(df['Registration Date'], errors='coerce')

# Get the columns to move
cols_to_move = ['First Name', 'Last Name']

# Create a list of columns to keep in the original order, excluding those to move
cols_to_keep = [col for col in df.columns if col not in cols_to_move]

# Reorder the columns, placing the specified columns at the beginning
df = df[cols_to_move + cols_to_keep]

# Function to check if a string is numeric
def is_numeric(s):
    try:
        float(s)  # Try converting to float to handle both integers and decimals
        return True
    except ValueError:
        return False

# Apply the function to the 'Phone' column and filter the DataFrame
numeric_phone_rows = df[df['Phone'].apply(is_numeric)]
non_numeric_phone_rows = df[~df['Phone'].apply(is_numeric)]

# Concatenate rows with non-numeric phone numbers to the garbage_bin DataFrame
garbage_bin = pd.concat([garbage_bin, non_numeric_phone_rows], ignore_index=True)

# Update df to only include rows with numeric phone numbers
df = numeric_phone_rows

print(df.head(20))
print(garbage_bin.head(20))

# Save the modified DataFrame to a new CSV file
output_file_path = '/content/drive/MyDrive/Protexxa/pionex/Second Attempt/processed_data.csv'
df.to_csv(output_file_path, index=False)  # Set index=False to avoid saving row indices

#Save garbage_bin to csv
garbage_output_file_path = '/content/drive/MyDrive/Protexxa/pionex/Second Attempt/garbage_data.csv'
garbage_bin.to_csv(garbage_output_file_path, index=False)

# prompt: generate code that drop all rows to the garbage_bin dataframe that have numbers contained in the First Name and Last Name Columns

# Assuming 'df' is your DataFrame and it has columns 'First Name' and 'Last Name'
# and 'garbage_bin' is your DataFrame to store dropped rows

# Function to check if a string contains any numbers
def contains_numbers(s):
  return any(char.isdigit() for char in s)

# Identify rows where 'First Name' or 'Last Name' contain numbers
rows_with_numbers = df[df['First Name'].apply(contains_numbers) | df['Last Name'].apply(contains_numbers)]

# Move those rows to the garbage_bin DataFrame
garbage_bin = pd.concat([garbage_bin, rows_with_numbers], ignore_index=True)

# Remove those rows from the original DataFrame
df = df[~df['First Name'].apply(contains_numbers) & ~df['Last Name'].apply(contains_numbers)]

# prompt: generate a code snippet that drops all rows with a single value in the First Name or Last Name column and saves it to the garbage_bin dataframe.  Then drop all rows with special characters like @, %, $ and #.  Save dropped values to garbage_bin dataframe

# Drop rows with single value in 'First Name' or 'Last Name'
single_value_rows = df[df['First Name'].apply(lambda x: len(str(x)) <=1) | df['Last Name'].apply(lambda x: len(str(x)) <= 1)]
garbage_bin = pd.concat([garbage_bin, single_value_rows], ignore_index=True)
df = df[~df['First Name'].apply(lambda x: len(str(x)) <= 1) & ~df['Last Name'].apply(lambda x: len(str(x)) <= 1)]

# Define special characters to remove
special_chars = ['@', '%', '$', '#']

# Function to check for special characters
def contains_special_chars(text):
  for char in special_chars:
    if char in str(text):
      return True
  return False

# Drop rows with special characters in 'First Name' or 'Last Name'
special_char_rows = df[df['First Name'].apply(contains_special_chars) | df['Last Name'].apply(contains_special_chars)]
garbage_bin = pd.concat([garbage_bin, special_char_rows], ignore_index = True)
df = df[~df['First Name'].apply(contains_special_chars) & ~df['Last Name'].apply(contains_special_chars)]

# prompt: generate code that moves the First Name and Last Name Columns to the front of the dataframe

# Get the columns to move
cols_to_move = ['First Name', 'Last Name']

# Create a list of columns to keep in the original order, excluding those to move
cols_to_keep = [col for col in df.columns if col not in cols_to_move]

# Reorder the columns, placing the specified columns at the beginning
df = df[cols_to_move + cols_to_keep]

print(df.head(20))

# prompt: generate code that drops rows with missing values in Registration Date and Registration Time columns and saves all dropped data to garbage_bin dataframe

# Drop rows with missing values in 'Registration Date' or 'Registration Time'
missing_registration_rows = df[df['Registration Date'].isna() | df['Registration Time'].isna()]
garbage_bin = pd.concat([garbage_bin, missing_registration_rows], ignore_index=True)
df = df.dropna(subset=['Registration Date', 'Registration Time'])

# prompt: generate a code snippet that checks the Phone column to ensure all values are numerial, if the values are not numerical drop the row and save it to the garbage_bin dataframe

# Function to check if a string is numeric
def is_numeric(s):
    try:
        float(s)  # Try converting to float to handle both integers and decimals
        return True
    except ValueError:
        return False

# Apply the function to the 'Phone' column and filter the DataFrame
numeric_phone_rows = df[df['Phone'].apply(is_numeric)]
non_numeric_phone_rows = df[~df['Phone'].apply(is_numeric)]

# Concatenate rows with non-numeric phone numbers to the garbage_bin DataFrame
garbage_bin = pd.concat([garbage_bin, non_numeric_phone_rows], ignore_index=True)

# Update df to only include rows with numeric phone numbers
df = numeric_phone_rows